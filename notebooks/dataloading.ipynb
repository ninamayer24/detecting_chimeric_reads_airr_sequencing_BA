{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ff1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 192 rows to /home-link/zxozk31/Analyse_cons_count/Results_analyse/chmmairra_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Pfade anpassen\n",
    "CHMM_ROOT = Path(\"/home-link/zxozk31/Analyse_cons_count/results_chmairra_sim6\")\n",
    "OUT_CSV   = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/chmmairra_metrics.csv\")\n",
    "\n",
    "# Sim-GT: sequence_id endet auf \"_chim<Zahl>\"\n",
    "RE_SIM_CHIM = re.compile(r\"_chim\\d+$\")\n",
    "\n",
    "def parse_sim_percent(dir_name: str) -> float:\n",
    "    token = dir_name.split(\"simulated_\", 1)[1].rstrip(\"p\")\n",
    "    return float(token.replace(\"_\", \".\"))\n",
    "\n",
    "def sample_base_from_stem(stem: str) -> str:\n",
    "    return re.sub(r\"_[0-9]+(?:_[0-9]+)?p_ig$\", \"\", stem)\n",
    "\n",
    "def main() -> None:\n",
    "    rows = []\n",
    "    for sim_dir in sorted(p for p in CHMM_ROOT.iterdir() if p.is_dir() and p.name.startswith(\"simulated_\")):\n",
    "        sim_percent = parse_sim_percent(sim_dir.name)\n",
    "\n",
    "        for chim_tsv in sim_dir.glob(\"*_chim.tsv\"):\n",
    "            common_stem = chim_tsv.name[:-len(\"_chim.tsv\")]\n",
    "            nonchim_tsv = chim_tsv.with_name(common_stem + \"_nonchim.tsv\")\n",
    "            if not nonchim_tsv.exists():\n",
    "                print(f\"[WARN] Missing non-chim file for {chim_tsv}\")\n",
    "                continue\n",
    "\n",
    "            df_chim = pd.read_csv(chim_tsv, sep=\"\\t\", dtype=str)\n",
    "            df_non  = pd.read_csv(nonchim_tsv, sep=\"\\t\", dtype=str)\n",
    "\n",
    "            n_chim, n_non = len(df_chim), len(df_non)\n",
    "            n_total = n_chim + n_non\n",
    "            pct_chim = (n_chim / n_total * 100.0) if n_total else 0.0\n",
    "\n",
    "            seq_chim = df_chim[\"sequence_id\"].astype(str)\n",
    "            seq_non  = df_non[\"sequence_id\"].astype(str)\n",
    "\n",
    "            TP = int(seq_chim.str.contains(RE_SIM_CHIM).sum())\n",
    "            FP = int(n_chim - TP)\n",
    "            FN = int(seq_non.str.contains(RE_SIM_CHIM).sum())\n",
    "            TN = int(n_non - FN)\n",
    "\n",
    "            rows.append({\n",
    "                \"sim_percent\": sim_percent,\n",
    "                \"sample\": common_stem,\n",
    "                \"method\": \"CHMMAIRRa\",\n",
    "                \"n_total\": n_total,\n",
    "                \"n_chim\": n_chim,\n",
    "                \"n_nonchim\": n_non,\n",
    "                \"pct_chim\": pct_chim,\n",
    "                \"sample_base\": sample_base_from_stem(common_stem),\n",
    "                \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=[\n",
    "        \"sim_percent\",\"sample\",\"method\",\"n_total\",\"n_chim\",\"n_nonchim\",\n",
    "        \"pct_chim\",\"sample_base\",\"TP\",\"FP\",\"TN\",\"FN\"\n",
    "    ])\n",
    "    out.sort_values(by=[\"sim_percent\",\"sample\"], inplace=True, kind=\"stable\")\n",
    "    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Wrote {len(out)} rows to {OUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8beba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_112321/2733400806.py:31: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 768 rows to /home-link/zxozk31/Analyse_cons_count/Results_analyse/vsearch_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Pfade anpassen\n",
    "VSEARCH_ROOT = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_vsearch_simulated6\")\n",
    "TRUTH_ROOT   = Path(\"/home-link/zxozk31/Analyse_cons_count/results_simulation6\")\n",
    "OUT_CSV      = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/vsearch_metrics.csv\")\n",
    "\n",
    "METHODS = [\"denovo\", \"ref\", \"uchime2\", \"uchime3\"]\n",
    "RE_CHIM_HDR = re.compile(r\"_chim\\d+(?:\\b|$)\")\n",
    "\n",
    "def parse_percent_token(name: str) -> tuple[str, float]:\n",
    "    m = re.search(r\"_([0-9]+(?:_[0-9]+)?)p(_|$)\", name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Missing percent token: {name}\")\n",
    "    token = m.group(1)\n",
    "    return token, float(token.replace(\"_\", \".\"))\n",
    "\n",
    "def derive_truth_path(result_dir: Path) -> tuple[str, str, float, Path]:\n",
    "    sample = result_dir.name.removesuffix(\"_all_chimera_out\")\n",
    "    token, sim_percent = parse_percent_token(sample)\n",
    "    truth_dir = TRUTH_ROOT / f\"simulated_{token}p\"\n",
    "    truth_fa  = truth_dir / f\"{sample}_all.fasta\"\n",
    "    return sample, token, sim_percent, truth_fa\n",
    "\n",
    "def read_fasta_split_truth(path: Path) -> tuple[set[str], set[str]]:\n",
    "    chim, non = set(), set()\n",
    "    if not path.exists():\n",
    "        return chim, non\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "        hdr, buf = None, []\n",
    "        def flush():\n",
    "            if hdr is None or not buf:\n",
    "                return\n",
    "            seq = \"\".join(buf).replace(\" \", \"\").replace(\"\\t\", \"\").strip().upper()\n",
    "            if seq:\n",
    "                (chim if RE_CHIM_HDR.search(hdr) else non).add(seq)\n",
    "        for line in fh:\n",
    "            if line.startswith(\">\"):\n",
    "                flush()\n",
    "                hdr, buf = line.strip(), []\n",
    "            else:\n",
    "                buf.append(line.strip())\n",
    "        flush()\n",
    "    return chim, non\n",
    "\n",
    "def read_fasta_seqs(path: Path) -> set[str]:\n",
    "    seqs, buf = set(), []\n",
    "    if not path.exists():\n",
    "        return seqs\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\">\"):\n",
    "                if buf:\n",
    "                    seqs.add(\"\".join(buf).replace(\" \", \"\").replace(\"\\t\", \"\").strip().upper())\n",
    "                    buf = []\n",
    "            else:\n",
    "                buf.append(line.strip())\n",
    "        if buf:\n",
    "            seqs.add(\"\".join(buf).replace(\" \", \"\").replace(\"\\t\", \"\").strip().upper())\n",
    "    return seqs\n",
    "\n",
    "def main() -> None:\n",
    "    rows = []\n",
    "    for rd in sorted(p for p in VSEARCH_ROOT.iterdir() if p.is_dir() and p.name.endswith(\"_all_chimera_out\")):\n",
    "        try:\n",
    "            sample, token, sim_percent, truth_fa = derive_truth_path(rd)\n",
    "        except ValueError as e:\n",
    "            print(f\"[WARN] {e}\")\n",
    "            continue\n",
    "\n",
    "        truth_chim_set, truth_nonchim_set = read_fasta_split_truth(truth_fa)\n",
    "        if not truth_chim_set and not truth_nonchim_set:\n",
    "            print(f\"[WARN] Truth FASTA missing/empty: {truth_fa}\")\n",
    "\n",
    "        sample_base = re.sub(rf\"_{re.escape(token)}p_.*$\", \"\", sample)\n",
    "\n",
    "        for m in METHODS:\n",
    "            chim_fa = rd / f\"chimeras_{m}.fa\"\n",
    "            non_fa  = rd / f\"nonchimeras_{m}.fa\"\n",
    "            if not chim_fa.exists() and not non_fa.exists():\n",
    "                continue\n",
    "\n",
    "            chim_set = read_fasta_seqs(chim_fa) if chim_fa.exists() else set()\n",
    "            non_set  = read_fasta_seqs(non_fa)  if non_fa.exists()  else set()\n",
    "\n",
    "            n_chim, n_non = len(chim_set), len(non_set)\n",
    "            n_total = n_chim + n_non\n",
    "            pct_chim = (100.0 * n_chim / n_total) if n_total else 0.0\n",
    "\n",
    "            TP = len(chim_set & truth_chim_set)\n",
    "            FP = len(chim_set & truth_nonchim_set)\n",
    "            FN = len(non_set & truth_chim_set)\n",
    "            TN = len(non_set & truth_nonchim_set)\n",
    "\n",
    "            rows.append({\n",
    "                \"sim_percent\": sim_percent,\n",
    "                \"sample\": sample,\n",
    "                \"method\": f\"VSEARCH_{m}\",\n",
    "                \"n_total\": n_total,\n",
    "                \"n_chim\": n_chim,\n",
    "                \"n_nonchim\": n_non,\n",
    "                \"pct_chim\": pct_chim,\n",
    "                \"sample_base\": sample_base,\n",
    "                \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"sim_percent\",\"sample\",\"method\",\"n_total\",\"n_chim\",\"n_nonchim\",\n",
    "        \"pct_chim\",\"sample_base\",\"TP\",\"FP\",\"TN\",\"FN\"\n",
    "    ])\n",
    "    df.sort_values([\"sim_percent\",\"sample\",\"method\"], inplace=True, kind=\"stable\")\n",
    "    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Wrote {len(df)} rows to {OUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42021884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 192 rows to /home-link/zxozk31/Analyse_cons_count/Results_analyse/usearch_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ROOT        = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_vsearch_simulated6\")\n",
    "TRUTH_ROOT  = Path(\"/home-link/zxozk31/Analyse_cons_count/results_simulation6\")\n",
    "OUT_CSV     = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/usearch_metrics.csv\")\n",
    "\n",
    "RE_CHIM_HDR = re.compile(r\"_chim\\d+(?:\\b|$)\")\n",
    "\n",
    "def parse_percent_token(name: str) -> tuple[str, float]:\n",
    "    m = re.search(r\"_([0-9]+(?:_[0-9]+)?)p(_|$)\", name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Kein Prozent-Token in: {name}\")\n",
    "    token = m.group(1)\n",
    "    return token, float(token.replace(\"_\", \".\"))\n",
    "\n",
    "def derive_truth_path(result_dir: Path) -> tuple[str, str, float, Path]:\n",
    "    \"\"\"Ordner '<sample>_<token>p_all_chimera_out' -> Truth: results_simulation6/simulated_<token>p/<sample>_<token>p_all.fasta\"\"\"\n",
    "    sample = result_dir.name.removesuffix(\"_all_chimera_out\")\n",
    "    token, sim_percent = parse_percent_token(sample)\n",
    "    truth_fa = TRUTH_ROOT / f\"simulated_{token}p\" / f\"{sample}_all.fasta\"\n",
    "    return sample, token, sim_percent, truth_fa\n",
    "\n",
    "def read_fasta_split_truth(path: Path) -> tuple[set[str], set[str]]:\n",
    "    r\"\"\"\n",
    "    Splittet Truth per Header:\n",
    "      - Header mit '_chim\\d+'  -> truth_chim_set\n",
    "      - sonst                  -> truth_nonchim_set\n",
    "    Vergleich über Sequenz (Uppercase, ohne Whitespace).\n",
    "    \"\"\"\n",
    "    chim, non = set(), set()\n",
    "    if not path.exists():\n",
    "        return chim, non\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "        hdr, buf = None, []\n",
    "        def flush():\n",
    "            if hdr is None or not buf: return\n",
    "            seq = \"\".join(buf).replace(\" \", \"\").replace(\"\\t\", \"\").strip().upper()\n",
    "            if not seq: return\n",
    "            (chim if RE_CHIM_HDR.search(hdr) else non).add(seq)\n",
    "        for line in fh:\n",
    "            if line.startswith(\">\"):\n",
    "                flush()\n",
    "                hdr, buf = line.strip(), []\n",
    "            else:\n",
    "                buf.append(line.strip())\n",
    "        flush()\n",
    "    return chim, non\n",
    "\n",
    "def read_fasta_set(path: Path) -> set[str]:\n",
    "    \"\"\"FASTA -> Menge der Sequenzen (Uppercase, ohne Whitespace).\"\"\"\n",
    "    s, buf = set(), []\n",
    "    if not path.exists():\n",
    "        return s\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\">\"):\n",
    "                if buf:\n",
    "                    s.add(\"\".join(buf).replace(\" \", \"\").replace(\"\\t\", \"\").strip().upper())\n",
    "                    buf = []\n",
    "            else:\n",
    "                buf.append(line.strip())\n",
    "        if buf:\n",
    "            s.add(\"\".join(buf).replace(\" \", \"\").replace(\"\\t\", \"\").strip().upper())\n",
    "    return s\n",
    "\n",
    "def find_first(p: Path, patterns: list[str]) -> Path | None:\n",
    "    for pat in patterns:\n",
    "        hits = list(p.glob(pat))\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    return None\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Alle USEARCH-Ordner \n",
    "for rd in sorted(p for p in ROOT.iterdir() if p.is_dir() and p.name.endswith(\"_all_chimera_out\")):\n",
    "    try:\n",
    "        sample, token, sim_percent, truth_fa = derive_truth_path(rd)\n",
    "    except ValueError as e:\n",
    "        print(f\"[WARN] {e}\")\n",
    "        continue\n",
    "\n",
    "    truth_chim_set, truth_nonchim_set = read_fasta_split_truth(truth_fa)\n",
    "    if not truth_chim_set and not truth_nonchim_set:\n",
    "        print(f\"[WARN] Truth FASTA leer/nicht gefunden: {truth_fa}\")\n",
    "\n",
    "    # USEARCH-Dateien suchen\n",
    "    chim_fa = find_first(rd, [\"*_all_ch.fa\"])\n",
    "    non_fa  = find_first(rd, [\"*_all_nonch.fa\"])\n",
    "\n",
    "    if chim_fa is None and non_fa is None:\n",
    "        continue\n",
    "\n",
    "    chim_set = read_fasta_set(chim_fa) if chim_fa else set()\n",
    "    non_set  = read_fasta_set(non_fa)  if non_fa  else set()\n",
    "\n",
    "    n_chim   = len(chim_set)\n",
    "    n_non    = len(non_set)\n",
    "    n_total  = n_chim + n_non\n",
    "    pct_chim = (100.0 * n_chim / n_total) if n_total else 0.0\n",
    "\n",
    "   \n",
    "    TP = len(chim_set & truth_chim_set)\n",
    "    FP = len(chim_set & truth_nonchim_set)\n",
    "    FN = len(non_set & truth_chim_set)\n",
    "    TN = len(non_set & truth_nonchim_set)\n",
    "\n",
    "    sample_base = re.sub(rf\"_{re.escape(token)}p_.*$\", \"\", sample)\n",
    "\n",
    "    rows.append({\n",
    "        \"sim_percent\": sim_percent,\n",
    "        \"sample\": sample,                  \n",
    "        \"method\": \"USEARCH\",\n",
    "        \"n_total\": n_total,\n",
    "        \"n_chim\": n_chim,\n",
    "        \"n_nonchim\": n_non,\n",
    "        \"pct_chim\": pct_chim,\n",
    "        \"sample_base\": sample_base,\n",
    "        \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN,\n",
    "    })\n",
    "\n",
    "# CSV schreiben\n",
    "df = pd.DataFrame(rows, columns=[\n",
    "    \"sim_percent\",\"sample\",\"method\",\"n_total\",\"n_chim\",\"n_nonchim\",\n",
    "    \"pct_chim\",\"sample_base\",\"TP\",\"FP\",\"TN\",\"FN\"\n",
    "])\n",
    "df.sort_values([\"sim_percent\",\"sample\"], inplace=True, kind=\"stable\")\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Wrote {len(df)} rows to {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a6026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote merged CSV with 1152 rows -> /home-link/zxozk31/Analyse_cons_count/Results_analyse/all_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Eingaben\n",
    "FILES = [\n",
    "    Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/vsearch_metrics.csv\"),\n",
    "    Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/usearch_metrics.csv\"),\n",
    "    Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/chmmairra_metrics.csv\"),\n",
    "]\n",
    "\n",
    "OUT_CSV = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/all_metrics.csv\")\n",
    "\n",
    "dfs = []\n",
    "for f in FILES:\n",
    "    if f.exists():\n",
    "        df = pd.read_csv(f)\n",
    "        dfs.append(df)\n",
    "    else:\n",
    "        print(f\"[WARN] Datei fehlt: {f}\")\n",
    "\n",
    "if not dfs:\n",
    "    raise SystemExit(\"Keine Eingabedateien gefunden!\")\n",
    "\n",
    "# Zusammenführen\n",
    "out = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sortierung: erst sim_percent, dann sample, dann method\n",
    "sort_cols = [c for c in [\"sim_percent\", \"sample\", \"method\"] if c in out.columns]\n",
    "if sort_cols:\n",
    "    out.sort_values(by=sort_cols, inplace=True, kind=\"stable\")\n",
    "\n",
    "# Schreiben\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Wrote merged CSV with {len(out)} rows -> {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e83f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 48 rows to /home-link/zxozk31/Analyse_cons_count/Results_analyse/unsim_vsearch_combined.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "VSEARCH_ROOT = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_vsearch_unsimulated2\")\n",
    "OUT_CSV      = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/unsim_vsearch_combined.csv\")\n",
    "\n",
    "RE_CHIMERAS = re.compile(r\"^chimeras_(?P<method>[^.]+)\\.fa$\")\n",
    "\n",
    "def fasta_count(path: Path) -> int:\n",
    "    if not path or not path.exists():\n",
    "        return 0\n",
    "    n = 0\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\">\"):\n",
    "                n += 1\n",
    "    return n\n",
    "\n",
    "def collect_vsearch_unsim(root: Path) -> list[dict]:\n",
    "    rows = []\n",
    "\n",
    "    run_dirs = sorted(p for p in root.iterdir() if p.is_dir() and p.name.endswith(\"_chimera_out\"))\n",
    "    for rd in run_dirs:\n",
    "        sample = rd.name.removesuffix(\"_chimera_out\")\n",
    "\n",
    "        for chim_fa in rd.glob(\"chimeras_*.fa\"):\n",
    "            m = RE_CHIMERAS.match(chim_fa.name)\n",
    "            if not m:\n",
    "                continue\n",
    "            method = m.group(\"method\")  # z.B. \"uchime2\", \"denovo\", \"ref\", \"uchime3\", ...\n",
    "\n",
    "            non_fa = rd / f\"nonchimeras_{method}.fa\"  \n",
    "            # Wenn weder chim noch non existiert, überspringen\n",
    "            if not chim_fa.exists() and not non_fa.exists():\n",
    "                continue\n",
    "\n",
    "            n_chim = fasta_count(chim_fa) if chim_fa.exists() else 0\n",
    "            n_non  = fasta_count(non_fa)  if non_fa.exists()  else 0\n",
    "            n_tot  = n_chim + n_non\n",
    "            pct    = round(100.0 * n_chim / n_tot, 2) if n_tot else 0.0\n",
    "\n",
    "            rows.append({\n",
    "                \"sample\": sample,\n",
    "                \"method\": f\"VSEARCH_{method}\",\n",
    "                \"n_total\": n_tot,\n",
    "                \"n_chim\": n_chim,\n",
    "                \"n_nonchim\": n_non,\n",
    "                \"pct_chim\": pct,\n",
    "                \"path_chim\": str(chim_fa) if chim_fa.exists() else \"\",\n",
    "                \"path_nonchim\": str(non_fa) if non_fa.exists() else \"\",\n",
    "            })\n",
    "\n",
    "        # Optional: falls es eine Methode gibt, für die nur nonchimeras_*.fa existiert:\n",
    "        for non_fa in rd.glob(\"nonchimeras_*.fa\"):\n",
    "            method = non_fa.stem.replace(\"nonchimeras_\", \"\")\n",
    "            # wurde diese Methode oben schon durch chimeras_* abgedeckt?\n",
    "            if any(r[\"sample\"] == sample and r[\"method\"] == f\"VSEARCH_{method}\" for r in rows):\n",
    "                continue\n",
    "            chim_fa = rd / f\"chimeras_{method}.fa\"\n",
    "            n_chim = fasta_count(chim_fa) if chim_fa.exists() else 0\n",
    "            n_non  = fasta_count(non_fa)\n",
    "            n_tot  = n_chim + n_non\n",
    "            pct    = round(100.0 * n_chim / n_tot, 2) if n_tot else 0.0\n",
    "            rows.append({\n",
    "                \"sample\": sample,\n",
    "                \"method\": f\"VSEARCH_{method}\",\n",
    "                \"n_total\": n_tot,\n",
    "                \"n_chim\": n_chim,\n",
    "                \"n_nonchim\": n_non,\n",
    "                \"pct_chim\": pct,\n",
    "                \"path_chim\": str(chim_fa) if chim_fa.exists() else \"\",\n",
    "                \"path_nonchim\": str(non_fa),\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "def main():\n",
    "    rows = collect_vsearch_unsim(VSEARCH_ROOT) if VSEARCH_ROOT.exists() else []\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"sample\",\"method\",\"n_total\",\"n_chim\",\"n_nonchim\",\"pct_chim\",\"path_chim\",\"path_nonchim\"\n",
    "    ])\n",
    "    if not df.empty:\n",
    "        df.sort_values([\"sample\",\"method\"], inplace=True, kind=\"stable\")\n",
    "    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Wrote {len(df)} rows to {OUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: 72 Zeilen -> /home-link/zxozk31/Analyse_cons_count/Results_analyse/unsimulated_combined_allmethods.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# === Eingaben anpassen ===\n",
    "CSV1 = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/unsim_usearch_only.csv\")\n",
    "CSV2 = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/unsim_vsearch_combined.csv\")\n",
    "CSV3 = Path(\"/home-link/zxozk31/Analyse_cons_count/results_unsimulated_chmmairra/chimera_eval_unsim_summary.csv\")\n",
    "\n",
    "OUT  = Path(\"/home-link/zxozk31/Analyse_cons_count/Results_analyse/unsimulated_combined_allmethods.csv\")\n",
    "\n",
    "# Erwartete Spalten (werden vereinheitlicht)\n",
    "COLUMNS = [\"sample\",\"method\",\"n_total\",\"n_chim\",\"n_nonchim\",\"pct_chim\",\"path_chim\",\"path_nonchim\"]\n",
    "\n",
    "def load_csv(p: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(p)\n",
    "    # fehlende Spalten ergänzen, extra Spalten ignorieren\n",
    "    for c in COLUMNS:\n",
    "        if c not in df.columns:\n",
    "            df[c] = \"\" if c.startswith(\"path_\") else 0\n",
    "    # nur relevante Spalten behalten & Reihenfolge fixieren\n",
    "    df = df[COLUMNS]\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    frames = [load_csv(p) for p in [CSV1, CSV2, CSV3]]\n",
    "    merged = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Duplikate entfernen (vollständige Zeilengleichheit)\n",
    "    merged = merged.drop_duplicates()\n",
    "\n",
    "    # sinnvolle Sortierung\n",
    "    if {\"sample\",\"method\"}.issubset(merged.columns):\n",
    "        merged = merged.sort_values([\"sample\",\"method\"], kind=\"stable\")\n",
    "\n",
    "    OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    merged.to_csv(OUT, index=False)\n",
    "    print(f\"OK: {len(merged)} Zeilen -> {OUT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
